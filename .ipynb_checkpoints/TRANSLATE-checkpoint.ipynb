{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZJsH6GX3LcU"
   },
   "source": [
    "## \"journal pacifique\" web bot\n",
    "parses sources for new articles, translates them into target languages [\"es\",\"pt\",\"pl\",\"zh-CN\",\"hr\"]. Wraps it up in a simple html document and writes it out to the appropriate directory.\n",
    "\n",
    "### TO DO:\n",
    "\n",
    "*   resizable design\n",
    "*   implement an automatic parser\n",
    "*   mobile-friendly design\n",
    "*   detect and highlight keywords\n",
    "*   automatic git push\n",
    "*   run the script on an aws server\n",
    "*   maybe a language rating mechanism?\n",
    "translations under a certain quality are dispensable\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "id": "am1FAv62IYw-",
    "outputId": "434c8443-c0ee-4244-b95e-a8f09b9970bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n",
      "Requirement already satisfied: mechanize in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
      "Requirement already satisfied: html5lib>=0.999999999 in /usr/local/lib/python3.6/dist-packages (from mechanize) (1.0.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib>=0.999999999->mechanize) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from html5lib>=0.999999999->mechanize) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans\n",
    "!pip install mechanize\n",
    "\n",
    "## Character limit: 15K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcmCkaflIcmH"
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import re\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSj3rydyWNvr"
   },
   "outputs": [],
   "source": [
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gg1MHPIoPIKG"
   },
   "outputs": [],
   "source": [
    "def string_strip(s):\n",
    "    return re.sub(r\"[^A-Za-z0-9]\", \"-\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cFY6cTtOwLM"
   },
   "outputs": [],
   "source": [
    "def sciencedaily_parse_links():\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-z6efhTaAfI"
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "\n",
    "def sciencedaily_parse_article(url):\n",
    "  \n",
    "    site = url\n",
    "    html_string = \"\"\n",
    "    tagged_w_ps = \"\"\n",
    "\n",
    "    # parse html\n",
    "\n",
    "    req = Request(ex_sd, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    html_string = webpage.decode(\"utf-8\") \n",
    "  \n",
    "    # get info\n",
    "  \n",
    "    # get the headline\n",
    "\n",
    "    headline = find_between(html_string, '<h1 id=\"headline\" class=\"headline\">','</h1>')\n",
    "  \n",
    "    # get the meta\n",
    "  \n",
    "    meta     = find_between(html_string, '<dd id=\"abstract\">','</dd>')\n",
    "  \n",
    "    # get the img address\n",
    "  \n",
    "    imgaddr  = find_between(html_string, 'center-block\" src=\"','\"')\n",
    "    if(imgaddr!=\"\"):\n",
    "        imgaddr  = 'https://www.sciencedaily.com'+imgaddr\n",
    "    else:\n",
    "        imgaddr  = '../../dummy.jpeg'\n",
    "  \n",
    "    # get the img alt\n",
    "  \n",
    "    imgalt   = find_between(html_string, '<div class=\"photo-caption\">','</div>')\n",
    "    cred     = '\\t'+find_between(html_string, '<div class=\"photo-credit\"><em>','</div>')\n",
    "  \n",
    "    # get the citation\n",
    "  \n",
    "    citation = find_between(html_string, '<div role=\"tabpanel\" class=\"tab-pane active\" id=\"citation_mla\">','</div>')\n",
    "  \n",
    "    \n",
    "    # get the article itself\n",
    "\n",
    "    article  = find_between(html_string, '<div id=\"text\">','</div>')\n",
    "    article  = re.sub(r\"<p>\" ,     \"\", article)\n",
    "    article  = re.sub(r\"</p>\", \"\\n\", article)\n",
    "  \n",
    "    # get the href at the end if it exists\n",
    "    href_tab = \"\"\n",
    "    href_tab = href_tab + find_between(article, '<a href','</a>')\n",
    "  \n",
    "    # delete the href and useless tags from the article\n",
    "  \n",
    "    article  = re.sub(r\"<a href.*?</a>\", \"\", article)\n",
    "    article  = re.sub(r\"<.*?>\", \"\",          article)\n",
    "    article  = re.sub(r\" -- \", \", \",         article)\n",
    "  \n",
    "    # special characters, this list will expand.\n",
    "  \n",
    "    #article  = re.sub(r\"&uuml;\", \"ü\",         article)\n",
    "    #article  = re.sub(r\"&ouml;\", \"ö\",         article)\n",
    "    #article  = re.sub(r\"&eacute;\", \"e\",         article)\n",
    "    # new sltn:\n",
    "    import html\n",
    "    article   = html.unescape(article)\n",
    "      \n",
    "    return {\"headline\": headline, \"meta\": meta, \"imgaddr\": imgaddr, \"imgalt\": imgalt, \"imgcredit\":cred,\"citation\": citation, \"article\": article, \"href\": href_tab}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9bqtXa0mCjf"
   },
   "outputs": [],
   "source": [
    "def get_translation(article_dictionary,target_language):\n",
    "    translations = {}\n",
    "    for key in article_dictionary:\n",
    "        print(key)\n",
    "        if(key!=\"citation\" and key!=\"imgcredit\" and key!= \"imgaddr\" and key!=\"href\"):\n",
    "            translations[key] = translator.translate(article_dictionary[key],dest=target_language).text\n",
    "  \n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcFIKve4csNY"
   },
   "outputs": [],
   "source": [
    "def get_language_dictionary(target_language):\n",
    "    ld = {}\n",
    "    words = [\"journal pacifique\", \"homepage\", \"archive\", \"about us\", \"source:\"]\n",
    "    for word in words:\n",
    "        ld[word] = translator.translate(word, dest=target_language).text\n",
    "    return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSvSx7ACTufo"
   },
   "outputs": [],
   "source": [
    "def html_from_dictionary(vanilla_dictionary, translated_dictionary, language_dictionary): # translated & language could be just one dictionary this was stupid.\n",
    "  \n",
    "    from datetime import date\n",
    "    hoy  = date.today()\n",
    "    d1   = hoy.strftime(\"%d/%m/%Y\")\n",
    "  \n",
    "    template  =\"https://journalpacifique.com/jp.temp\"\n",
    "    req       = Request(template, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage   = urlopen(req).read()\n",
    "\n",
    "    html = webpage.decode(\"utf-8\") \n",
    "  \n",
    "    html_article = re.sub(r\"\\n\\n\", \"</p>\\n\\n<p>\",   translated_dictionary[\"article\"])\n",
    "    html_article = \"<p>\" + html_article + \"</p>\"\n",
    "  \n",
    "    print(translated_dictionary)\n",
    "    print(language_dictionary)\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$article-title%%\",  translated_dictionary[\"headline\"],         html)\n",
    "    html = re.sub(r\"\\$\\$img-alt%%\",        translated_dictionary[\"imgalt\"],           html)\n",
    "    html = re.sub(r\"\\$\\$article-meta%%\",   translated_dictionary[\"meta\"],             html)\n",
    "    html = re.sub(r\"\\$\\$source%%\",         vanilla_dictionary[\"citation\"],            html)\n",
    "    html = re.sub(r\"\\$\\$img.jpg%%\",        vanilla_dictionary[\"imgaddr\"],             html)\n",
    "    html = re.sub(r\"\\$\\$article-text%%\",   html_article                  ,            html)\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$home%%\",           language_dictionary[\"homepage\"],           html)\n",
    "    html = re.sub(r\"\\$\\$archive%%\",        language_dictionary[\"archive\"],            html)\n",
    "    html = re.sub(r\"\\$\\$about%%\",          language_dictionary[\"about us\"],           html)\n",
    "    html = re.sub(r\"\\$\\$jp-translation%%\", language_dictionary[\"journal pacifique\"],  html)\n",
    "    html = re.sub(r\"\\$\\$taken-from%%\",     language_dictionary[\"source:\"],            html)\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$imgcredit%%\",       vanilla_dictionary[\"imgcredit\"],          html)\n",
    "  \n",
    "    html = re.sub(r\"<a\",       '<a style=\"color:black\"',          html)\n",
    "  \n",
    "  \n",
    "  \n",
    "    html = re.sub(r\"\\$\\$href%%\",           vanilla_dictionary[\"href\"],            html)\n",
    "  \n",
    "    html = re.sub(r\"-- \", \",\",  html)\n",
    " \n",
    "    html = re.sub(r\"\\$\\$date%%\", d1, html)\n",
    "  \n",
    "    #html = re.sub(r'</head>', '<style> p { text-indent: 30px;} </style>\\n\\t</head>', html)\n",
    "  \n",
    "    return html\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8_T668O03h9"
   },
   "outputs": [],
   "source": [
    "def getnewpath(dic):\n",
    "  \n",
    "    from datetime import date\n",
    "    hoy  = date.today()\n",
    "    date = hoy.strftime(\"%Y-%m-%d\")\n",
    "  \n",
    "    urlheadline = string_strip(dic[\"headline\"])\n",
    "    newpathaddr = target_language+\"/posts/\"+date+\"/\"\n",
    "    newheadline = newpathaddr+urlheadline+\".html\"\n",
    "    \n",
    "    if newheadline in headlinessofar:\n",
    "        c=2\n",
    "        while (newheadline[:-5]+repr(c)+newheadline[-5:] in headlinessofar):\n",
    "            c+=1\n",
    "        newheadline = newheadline[:-5]+repr(c)+newheadline[-5:]\n",
    "    \n",
    "    headlinessofar.append(newheadline)\n",
    "    return [newheadline,newpathaddr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyhS7v6RUPR4"
   },
   "outputs": [],
   "source": [
    "def url_to_dirfile(url,target_language):\n",
    "    zh_ld = get_language_dictionary(target_language)\n",
    "    ar_di = sciencedaily_parse_article(url)\n",
    "\n",
    "    tr_di = get_translation(ar_di,target_language)\n",
    "    htmlx = html_from_dictionary(ar_di,tr_di,zh_ld)\n",
    "  \n",
    "    newdirs = getnewpath(ar_di)\n",
    "  \n",
    "    import os\n",
    "    cmd = \"mkdir -p \"+newdirs[1]\n",
    "    os.system(cmd)\n",
    "  \n",
    "    f= open(newdirs[0],\"w+\")\n",
    "    f.write(htmlx)\n",
    "  \n",
    "    return htmlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Or4n3Fx01Mu"
   },
   "outputs": [],
   "source": [
    "headlinessofar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\"https://www.sciencedaily.com/releases/2019/09/190910080021.htm\",\n",
    "            \"https://www.sciencedaily.com/releases/2019/09/190911174649.htm\",\n",
    "            \"https://www.sciencedaily.com/releases/2019/09/190911142815.htm\",\n",
    "            \"https://www.sciencedaily.com/releases/2019/09/190911142740.htm\",\n",
    "            \"https://www.sciencedaily.com/releases/2019/09/190911142736.htm\",\n",
    "            \"https://www.sciencedaily.com/releases/2019/09/190911121952.htm\",\n",
    "           ]   \n",
    "            \n",
    "languages = [\"de\",\"es\",\"pt\",\"pl\",\"zh-CN\",\"hr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "colab_type": "code",
    "id": "F5uaV7Za0s9w",
    "outputId": "7fcb5617-670a-4d19-b6b6-e3b2784a0ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline\n",
      "meta\n",
      "imgaddr\n",
      "imgalt\n",
      "imgcredit\n",
      "citation\n",
      "article\n",
      "href\n",
      "{'headline': '新的飞行爬行动物物种是有史以来最大的飞行动物之一', 'meta': '根据一项新的研究，一种新发现的翼龙属是有史以来最大的飞行动物。', 'imgalt': '翼龙在飞行中（储蓄图象）的例证。', 'article': '来自Azhdarchid翼龙（通常被错误地称为“翼龙”）的Cryodrakon boreas是一种飞行爬行动物，翼展高达10米，生活在大约7700万年前的白垩纪时期。\\n\\n它的遗体是30年前在加拿大阿尔伯塔省发现的，但古生物学家认为它们属于在美国德克萨斯州发现的已知的翼龙种，名为Quetzalcoatlus。\\n\\n该研究发表在“脊椎动物古生物学杂志”上，揭示它实际上是一种新物种，也是加拿大首次发现的翼龙。\\n\\n伦敦玛丽女王大学研究的主要作者David Hone博士说：“这是一个很酷的发现，我们知道这种动物在这里，但现在我们可以证明它与其他azhdarchids不同，所以它得名。”\\n\\n虽然由具有部分翅膀，腿部，颈部和肋骨的骨架组成的遗骸最初被分配给Quetzalcoatlus，但多年来发现的这种和其他材料的研究表明，鉴于人们日益增长的理解，它是一个不同的物种。 azhdarchid多样性。\\n\\n主要骨骼来自一只翼展约5米的幼小动物，但另一个标本的一个巨大骨颈表明成年动物的翼展约为10米。\\n\\n这使得Cryodrakon boreas在尺寸上与其他巨型azhdacids相当，包括Texan Quetzalcoatlus，翼展可达10.5米，重约250公斤。\\n\\n像其他azhdarchids一样，这些动物是食肉动物，主要以小动物为主，可能包括蜥蜴，哺乳动物甚至婴儿恐龙。\\n\\nHone博士补充说：“我们可以确定Cryodrakon与Quetzalcoatlus不同，因为它意味着我们可以更好地了解北美掠食性翼龙的多样性和进化。”\\n\\n与大多数翼龙群不同，azhdarchids主要来自陆地环境，尽管它们有可能在飞行中穿越海洋距离，但它们被广泛认为是适应和生活在内陆环境中的动物。\\n\\n尽管它们规模庞大，分布在北美洲，南美洲，亚洲，非洲和欧洲，但很少有人知道它们不仅仅是零碎的遗骸。这使得Cryodrakon成为一种重要的动物，因为它具有保存完好的骨骼，并且包括多个不同大小的个体。'}\n",
      "{'journal pacifique': '和平的报纸', 'homepage': '主页', 'archive': '档案', 'about us': '关于我们', 'source:': '资源：'}\n"
     ]
    }
   ],
   "source": [
    "for target_language in languages:\n",
    "    for article in articles:\n",
    "        tmp = url_to_dirfile(ex_sd,target_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLMAwueUAB1f"
   },
   "outputs": [],
   "source": [
    "#print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLA2Xs8wUQYx"
   },
   "outputs": [],
   "source": [
    "ls -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7tM1pNHvsRo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgdwWqSBepZL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiGEb3gaxBDH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pSIzEoDzepNr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UciJeDgfqz3r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMFBjf5vqz6B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKuJ6WK3qz8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo1ubDJ8qz_P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKfQHt50q0Dx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIHb6cRlepob"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXLuwSPjXGx-"
   },
   "outputs": [],
   "source": [
    "\"\"\"#parse given url (for quanta mag) and return translation of the article.\n",
    "\n",
    "def quanta_parser(url, target_language='tr'):\n",
    "  site = url\n",
    "  html_string = \"\"\n",
    "  tagged_w_ps = \"\"\n",
    "\n",
    "  # parse html\n",
    "\n",
    "  from mechanize import Browser\n",
    "  br = Browser()\n",
    "  br.set_handle_robots(False) #illegal\n",
    "  br.open(site)\n",
    "  html = br.response().readlines()\n",
    "  for line in html:\n",
    "    html_string = html_string+line.decode(\"utf-8\") \n",
    "    \n",
    "    \n",
    "  # get text in the main section under <section> tag.  \n",
    "  \n",
    "  for item in html_string.split(\"</section>\"):\n",
    "    if \"<section>\" in item:\n",
    "      tagged_w_ps = tagged_w_ps + item[ item.find(\"<section>\")+len(\"<section>\") : ]\n",
    "      \n",
    "  \n",
    "  # get text in the paragraph tags (<p>).\n",
    "  \n",
    "  for item in html_string.split(\"</p>\"):\n",
    "    if \"<p>\" in item:\n",
    "      tagged_w_ps = tagged_w_ps + (item[ item.find(\"<p>\")+len(\"<p>\") : ]+\"ğ\")\n",
    "      \n",
    "      \n",
    "  # remove alt texts.\n",
    "  tagged_w_ps = re.sub(r\" *\\..*(Quanta Magazine)\", \".\", tagged_w_ps)\n",
    "      \n",
    "  \n",
    "  # take link tags out of the way and edit custom characters.\n",
    "  # TODO: expand this list for future articles with other unicode characters.\n",
    "      \n",
    "  newstr = re.sub(r\"(<a href).*?(\\\">)\", \"\", tagged_w_ps)\n",
    "  newstr = re.sub(r\"(\\\\u2018)\", \"\\\"\", newstr)\n",
    "  newstr = re.sub(r\"(\\\\u2019)\", \"\\\"\", newstr)\n",
    "  newstr = re.sub(r\"(\\xa0)\", \" \", newstr)\n",
    "  newstr = re.sub(r\"(&#8217)\", \"\\'\", newstr)\n",
    "  newstr = re.sub(r\"(</a>)\", \"\", newstr)\n",
    "  newstr = re.sub(r\"\\.<.*?(quote_attribution).*?<p>\", \" says \", newstr)\n",
    "  newstr = re.sub(r\"(<p>)\", \"\", newstr)\n",
    "  newstr = re.sub(r\"(<).*(>)\", \".\", newstr)\n",
    "  newstr = re.sub(r\"(\\\",\\\"caption).*}}\", \"\", newstr)\n",
    "  \n",
    "  \n",
    "  # convert custom newline tag to newline\n",
    "  newstr = re.sub(r\"ğ+\", \"\\n\\n\", newstr)\n",
    "  \n",
    "  # translate the text to your target language.\n",
    "  \n",
    "  translation = translator.translate(newstr, dest=target_language).text\n",
    "  \n",
    "  return translation\n",
    "  \n",
    "  \"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TRANSLATE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
