{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZJsH6GX3LcU"
   },
   "source": [
    "## \"journal pacifique\" web bot\n",
    "parses sources for new articles, translates them into target languages [\"es\",\"pt\",\"pl\",\"zh-CN\"]. Wraps it up in a simple html document and writes it out to the appropriate directory.\n",
    "\n",
    "#### TO DO TECHNICAL:\n",
    "\n",
    "*   save the articles dictionary as a json or something (__done__)\n",
    "*   *   (dic backup for later design changes) important\n",
    "*   implement an automatic parser (__done(sd)__)\n",
    "*   detect and highlight keywords\n",
    "*   automatic git push (__done__ but pass cache time should be increased)\n",
    "*   run the script on an aws server\n",
    "*   maybe an open source grammar rating mechanism?\n",
    "*   don't send a separate request to the website for every translation (__done__)\n",
    "*   same pages shouldn't be crawled twice. Even if they are crawled they shouldn't be overwritten. (__done__)\n",
    "*   implement waiting if requests exhaust limit\n",
    "*   also implement a timeout. maybe take articles into a queue.\n",
    "*   re-read SD's [terms](https://www.sciencedaily.com/terms.htm) on reproduction. (especially on images)\n",
    "*   take the bot 1 directory up so it won't be pushed into the public repo. (__done__)\n",
    "\n",
    "#### TO DO GRAPHICAL\n",
    "*   responsive text, currently changes size by page??\n",
    "*   resizable design (__done__)\n",
    "*   mobile-friendly design\n",
    "*   *   [media queries for different device widths](https://stackoverflow.com/questions/16387400/getting-the-right-font-size-on-every-mobile-device)\n",
    "*   subscribe and social media block\n",
    "\n",
    "\n",
    "#### POSSIBLE SOURCES\n",
    "*   [the conversation](https://theconversation.com/uk/republishing-guidelines)\n",
    "*   *   approval needed for translation\n",
    "*   \n",
    "\n",
    "NOTE: google transalte tokens refresh every hour (?)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "am1FAv62IYw-",
    "outputId": "a6430627-a1b7-4973-b011-c8db27c4d236"
   },
   "outputs": [],
   "source": [
    "#for colab\n",
    "#!pip install googletrans\n",
    "#!pip install mechanize\n",
    "\n",
    "## Character limit: 15K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#cmd = \"cd cemreefe.github.io; git pull; cd ..\"\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcmCkaflIcmH"
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import re\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSj3rydyWNvr"
   },
   "outputs": [],
   "source": [
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gg1MHPIoPIKG"
   },
   "outputs": [],
   "source": [
    "def string_strip(s):\n",
    "    return re.sub(r\"[^A-Za-z0-9]\", \"-\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-z6efhTaAfI"
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from random import randrange\n",
    "\n",
    "def sciencedaily_parse_article(url):\n",
    "  \n",
    "    site = url\n",
    "    html_string = \"\"\n",
    "    tagged_w_ps = \"\"\n",
    "\n",
    "    # parse html\n",
    "\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "\n",
    "    html_string = webpage.decode(\"utf-8\") \n",
    "  \n",
    "    # get info\n",
    "  \n",
    "    # get the headline\n",
    "\n",
    "    headline = find_between(html_string, '<h1 id=\"headline\" class=\"headline\">','</h1>')\n",
    "  \n",
    "    # get the meta\n",
    "  \n",
    "    meta     = find_between(html_string, '<dd id=\"abstract\">','</dd>')\n",
    "  \n",
    "    # get the img address\n",
    "  \n",
    "    imgaddr  = find_between(html_string, 'center-block\" src=\"','\"')\n",
    "    \n",
    "    # set imgaddr image from sciencedaily if it exists. Else use one of the dummy imgs.\n",
    "    \n",
    "    if(imgaddr!=\"\"):\n",
    "        imgaddr  = 'https://www.sciencedaily.com'+imgaddr\n",
    "    else:\n",
    "        imgaddr  = '../../../img/dummy'+repr(randrange(20))+'.jpeg'\n",
    "    \n",
    "    # get random image from dummies since sciencedaily images get dead links later on.\n",
    "    #imgaddr  = '../../../img/dummy'+repr(randrange(20))+'.jpeg'\n",
    "  \n",
    "    # get the img alt\n",
    "  \n",
    "    imgalt   = find_between(html_string, '<div class=\"photo-caption\">','</div>')\n",
    "    cred     = '\\t'+find_between(html_string, '<div class=\"photo-credit\"><em>','</div>')\n",
    "  \n",
    "    # get the citation\n",
    "  \n",
    "    citation = find_between(html_string, '<div role=\"tabpanel\" class=\"tab-pane active\" id=\"citation_mla\">','</div>')\n",
    "  \n",
    "    \n",
    "    # get the article itself\n",
    "\n",
    "    article  = find_between(html_string, '<div id=\"text\">','</div>')\n",
    "    article  = re.sub(r\"<p>\" ,     \"\", article)\n",
    "    article  = re.sub(r\"</p>\", \"\\n\", article)\n",
    "  \n",
    "    # get the href at the end if it exists\n",
    "    href_tab = \"\"\n",
    "    href_tab = href_tab + find_between(article, '<a href','</a>')\n",
    "  \n",
    "    # delete the href and useless tags from the article\n",
    "  \n",
    "    article  = re.sub(r\"<a href.*?</a>\", \"\", article)\n",
    "    article  = re.sub(r\"<.*?>\", \"\",          article)\n",
    "    article  = re.sub(r\" -- \", \", \",         article)\n",
    "  \n",
    "    # special characters, this list will expand.\n",
    "  \n",
    "    #article  = re.sub(r\"&uuml;\", \"ü\",         article)\n",
    "    #article  = re.sub(r\"&ouml;\", \"ö\",         article)\n",
    "    #article  = re.sub(r\"&eacute;\", \"e\",         article)\n",
    "    # new sltn:\n",
    "    import html\n",
    "    article   = html.unescape(article)\n",
    "      \n",
    "            #y                    #y                                #y                                                       #y                  \n",
    "    return {\"headline\": headline, \"meta\": meta, \"imgaddr\": imgaddr, \"imgalt\": imgalt, \"imgcredit\":cred,\"citation\": citation, \"article\": article, \"href\": href_tab}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9bqtXa0mCjf"
   },
   "outputs": [],
   "source": [
    "def get_translation(article_dictionary,target_language):\n",
    "    big_string= \"\"\n",
    "    translations = {}\n",
    "    token_in = \"(#@)\"\n",
    "    if (target_language==\"zh-CN\"):\n",
    "        token_out = \"（＃@）\"\n",
    "    else: token_out=\"(# @)\"\n",
    "      \n",
    "    \n",
    "    #sırası karışmasın!! keylerden array oluştur, arrayi itere et.\n",
    "    keys = [\"headline\",\"meta\",\"article\",\"imgalt\"]\n",
    "    \n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        if big_string != \"\":\n",
    "            big_string = big_string + token_in + article_dictionary[key]\n",
    "        else:\n",
    "            big_string = article_dictionary[key]\n",
    "            \n",
    "    big_translated_string = translator.translate(big_string,dest=target_language).text\n",
    "    \n",
    "    translations_array    = big_translated_string.split(token_out)\n",
    "   \n",
    "    #print(big_translated_string)\n",
    "    #print(len(translations_array),translations_array)\n",
    "    \n",
    "    for i in range (4):\n",
    "        translations[keys[i]]=translations_array[i]\n",
    "    translations[\"imgaddr\"]=article_dictionary[\"imgaddr\"]\n",
    "    translations[\"citation\"]=article_dictionary[\"citation\"]\n",
    "    translations[\"imgcredit\"]=article_dictionary[\"imgcredit\"]\n",
    "    translations[\"href\"]=article_dictionary[\"href\"]\n",
    "    translations[\"org-headline\"]=article_dictionary[\"headline\"]\n",
    "    translations[\"lang\"]=target_language\n",
    "    \n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RcFIKve4csNY"
   },
   "outputs": [],
   "source": [
    ";# deprecated\n",
    "def get_language_dictionary(target_language):\n",
    "    ld = {}\n",
    "    words = [\"journal pacifique\", \"homepage\", \"archive\", \"about us\", \"source:\"]\n",
    "    for word in words:\n",
    "        print(word)\n",
    "        ld[word] = translator.translate(word, dest=target_language).text\n",
    "    return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSvSx7ACTufo"
   },
   "outputs": [],
   "source": [
    "def html_from_dictionary(translated_dictionary, target_language, language_dictionary): # translated & language could be just one dictionary this was stupid.\n",
    "  \n",
    "    from datetime import date\n",
    "    hoy  = date.today()\n",
    "    d1   = hoy.strftime(\"%d/%m/%Y\")\n",
    "  \n",
    "    html = open(SUBFOLDER + \"jp.temp\").read()\n",
    "\n",
    "    html_article = re.sub(r\"\\n\\n\", \"</p>\\n\\n<p>\",   translated_dictionary[\"article\"])\n",
    "    html_article = \"<p>\" + html_article + \"</p>\"\n",
    "\n",
    "    print(translated_dictionary[\"headline\"])\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$article-title%%\",  translated_dictionary[\"headline\"],         html)\n",
    "    html = re.sub(r\"\\$\\$img-alt%%\",        translated_dictionary[\"imgalt\"],           html)\n",
    "    html = re.sub(r\"\\$\\$article-meta%%\",   translated_dictionary[\"meta\"],             html)\n",
    "    html = re.sub(r\"\\$\\$source%%\",         translated_dictionary[\"citation\"],            html)\n",
    "    html = re.sub(r\"\\$\\$img.jpg%%\",        translated_dictionary[\"imgaddr\"],             html)\n",
    "    html = re.sub(r\"\\$\\$article-text%%\",   html_article                  ,            html)\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$home%%\",           language_dictionary[\"homepage-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$archive%%\",        language_dictionary[\"archive-\"+target_language],            html)\n",
    "    html = re.sub(r\"\\$\\$about%%\",          language_dictionary[\"about us-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$jp-translation%%\", language_dictionary[\"journal pacifique-\"+target_language],  html)\n",
    "    html = re.sub(r\"\\$\\$taken-from%%\",     language_dictionary[\"source:-\"+target_language],            html)\n",
    "    html = re.sub(r\"\\$\\$target-languages%%\",     target_language,            html)\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$imgcredit%%\",       translated_dictionary[\"imgcredit\"],          html)\n",
    "  \n",
    "    html = re.sub(r\"\\$\\$href%%\",           translated_dictionary[\"href\"],            html)\n",
    "  \n",
    "    html = re.sub(r\"-- \", \",\",  html)\n",
    " \n",
    "    html = re.sub(r\"\\$\\$date%%\", d1, html)\n",
    "  \n",
    "    #html = re.sub(r'</head>', '<style> p { text-indent: 30px;} </style>\\n\\t</head>', html)\n",
    "  \n",
    "    return html\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8_T668O03h9"
   },
   "outputs": [],
   "source": [
    "def getnewpath(translated_dict):\n",
    "  \n",
    "    from datetime import date\n",
    "    hoy  = date.today()\n",
    "    date = hoy.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    translated_dict[\"date\"]=date\n",
    "  \n",
    "    urlheadline = string_strip(translated_dict[\"org-headline\"])+\"-\"+translated_dict[\"lang\"]\n",
    "    postsfolder = \"/posts/\"+date+\"/\"\n",
    "    newpathaddr = translated_dict[\"lang\"]+postsfolder\n",
    "    newheadline = newpathaddr+urlheadline+\".html\"\n",
    "    newheadlang = postsfolder+urlheadline+\".html\"\n",
    "    \n",
    "    translated_dict[\"pathfromhome\"]=newheadline\n",
    "    translated_dict[\"pathfromlang\"]=newheadlang\n",
    "    \n",
    "    # this was implemented for short headlines (~10char)\n",
    "    #if newheadline in headlinessofar:\n",
    "    #    c=2\n",
    "    #    while (newheadline[:-5]+repr(c)+newheadline[-5:] in headlinessofar):\n",
    "    #        c+=1\n",
    "    #    newheadline = newheadline[:-5]+repr(c)+newheadline[-5:]\n",
    "    \n",
    "    headlinessofar.append(newheadline)\n",
    "    return [newheadline,newpathaddr,urlheadline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBFOLDER = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HD6jZB1jmpVe"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(SUBFOLDER+'obj/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(SUBFOLDER+'obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5dlG_rpmpVm"
   },
   "outputs": [],
   "source": [
    "def dic_to_dirfile(dic,target_language, elements_dictionary):\n",
    "    \n",
    "    #we used to translate all elements at every step, now it is automated due to\n",
    "    #google translate's quota restrictions.\n",
    "    \n",
    "    #zh_ld = get_language_dictionary(target_language)\n",
    "\n",
    "    tr_di = get_translation(dic,target_language)\n",
    "    htmlx = html_from_dictionary(tr_di, target_language, elements_dictionary)\n",
    "  \n",
    "    newdirs = getnewpath(tr_di)\n",
    "  \n",
    "    import os\n",
    "    cmd = \"mkdir -p \"+SUBFOLDER+newdirs[1]\n",
    "    os.system(cmd)\n",
    "  \n",
    "    f= open(SUBFOLDER+newdirs[0],\"w+\")\n",
    "    f.write(htmlx)\n",
    "\n",
    "    return [htmlx,tr_di,newdirs[2],newdirs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def targdic_to_dirfile(tr_di,target_language, elements_dictionary):\n",
    "    \n",
    "    htmlx = html_from_dictionary(tr_di, target_language, elements_dictionary)\n",
    "  \n",
    "    newdirs = getnewpath(tr_di)\n",
    "  \n",
    "    import os\n",
    "    cmd = \"mkdir -p \"+SUBFOLDER+newdirs[1]\n",
    "    os.system(cmd)\n",
    "  \n",
    "    f= open(SUBFOLDER+newdirs[0],\"w+\")\n",
    "    f.write(htmlx)\n",
    "    \n",
    "    print(SUBFOLDER+newdirs[0])\n",
    "  \n",
    "    return [htmlx,tr_di,newdirs[2],newdirs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7W8jsdDvoxH"
   },
   "outputs": [],
   "source": [
    "elements_dictionary = {\n",
    "    \"journal pacifique-es\":\"periódico pacífico\", \n",
    "    \"journal pacifique-pt\":\"jornal pacífico\", \n",
    "    \"journal pacifique-tr\":\"barışçıl gazete\", \n",
    "    \"journal pacifique-zh-CN\":\"和平的报纸\", \n",
    "    \"journal pacifique-pl\":\"spokojna gazeta\", \n",
    "    \"journal pacifique-de\":\"friedliche Zeitung\", \n",
    "    \"journal pacifique-af\":\"vreedsame koerant\",\n",
    "    \n",
    "    \"homepage-es\":\"página principal\", \n",
    "    \"homepage-pt\":\"pagina inicial\", \n",
    "    \"homepage-tr\":\"anasayfa\",\n",
    "    \"homepage-pl\":\"strona główna\", \n",
    "    \"homepage-de\":\"Startseite\", \n",
    "    \"homepage-zh-CN\":\"主页\", \n",
    "    \"homepage-af\":\"tuisblad\", \n",
    "    \n",
    "    \"archive-es\":\"archivo\",\n",
    "    \"archive-pt\":\"arquivo\",\n",
    "    \"archive-tr\":\"arşiv\",\n",
    "    \"archive-zh-CN\":\"档案\",\n",
    "    \"archive-pl\":\"archiwum\",\n",
    "    \"archive-de\":\"Archiv\",\n",
    "    \"archive-af\":\"argief\",\n",
    "    \n",
    "    \n",
    "    \"about us-es\":\"sobre nosotros\",\n",
    "    \"about us-pt\":\"sobre nós\",\n",
    "    \"about us-tr\":\"hakkında\",\n",
    "    \"about us-zh-CN\":\"关于我们\",\n",
    "    \"about us-pl\":\"o nas\",\n",
    "    \"about us-de\":\"Über uns\",\n",
    "    \"about us-af\":\"oor ons\",\n",
    "    \n",
    "    \"source:-es\":\"fuente:\",\n",
    "    \"source:-pt\":\"fonte:\",\n",
    "    \"source:-tr\":\"kaynakça:\",\n",
    "    \"source:-zh-CN\":\"资源\",\n",
    "    \"source:-pl\":\"źródło\",\n",
    "    \"source:-de\":\"Quelle:\",\n",
    "    \"source:-af\":\"bron:\",\n",
    "    \n",
    "    \"latest-articles-es\":\"Últimos artículos\",\n",
    "    \"latest-articles-pt\":\"Artigos Mais Recentes\",\n",
    "    \"latest-articles-pl\":\"Ostatnie artykuły\",\n",
    "    \"latest-articles-zh-CN\":\"最新的文章\",\n",
    "    \"latest-articles-tr\":\"En yeni makaleler\",\n",
    "    \"latest-articles-de\":\"Neueste Artikel\",\n",
    "    \"latest-articles-af\":\"Mees onlangse artikels\",\n",
    "    \n",
    "    \"hometext-es\":\"Bienvenido a Journal Pacifique. Le proporcionamos los últimos artículos sobre ciencia y tecnología. Journal Pacifique se dedica a la distribución de investigaciones científicas populares en otros idiomas además del inglés.\",\n",
    "    \"hometext-pt\":\"Bem-vindo ao Journal Pacifique. Fornecemos os artigos mais recentes sobre ciência e tecnologia. O Journal Pacifique é dedicado à distribuição de pesquisas científicas populares em outros idiomas que não o inglês.\",\n",
    "    \"hometext-pl\":\"Witamy w Journal Pacifique. Zapewniamy najnowsze artykuły na temat nauki i technologii. Czasopismo Pacifique poświęcone jest rozpowszechnianiu popularnych badań naukowych w językach innych niż angielski.\",\n",
    "    \"hometext-zh-CN\":\"欢迎来到Journal Pacifique。 我们为您提供有关科学和技术的最新文章。 Journal Pacifique致力于以英语以外的语言分发流行的科学研究。\",\n",
    "    \"hometext-tr\":\"Journal Pacifique'e hoş geldiniz. Bilim ve teknoloji ile ilgili en son makaleleri size sunuyoruz. Journal Pacifique, popüler bilimsel araştırmaların İngilizce dışındaki dillerde dağıtımına adanmıştır.\",\n",
    "    \"hometext-de\":\"Willkommen im Journal Pacifique. Wir präsentieren Ihnen die neuesten Artikel über Wissenschaft und Technologie. Das Journal Pacifique widmet sich der Verbreitung populärwissenschaftlicher Forschung in anderen Sprachen als Englisch.\",\n",
    "    \"hometext-af\":\"Welkom by die Journal Pacifique. Ons bied die nuutste artikels oor wetenskap en tegnologie aan. Die Journal Pacifique is toegewy aan die verspreiding van populêre wetenskaplike navorsing in ander tale as Engels.\",\n",
    "    \n",
    "    \"abouttext-es\":\"Journal Pacifique se estableció para evitar que la barrera del idioma obstruya la accesibilidad de los artículos científicos. En Journal Pacifique pensamos que todos los artículos científicos deberían ser fácilmente accesibles para las personas en su propio idioma. Por lo tanto, hemos asumido la responsabilidad de encontrar artículos en Internet de valor decente y traducirlos a tantos idiomas como sea posible, haciéndolos accesibles a muchas más personas de lo que era posible en su idioma original.\",\n",
    "    \"abouttext-pt\":\"O Journal Pacifique foi criado para impedir que a barreira do idioma obstrua a acessibilidade de artigos científicos. No Journal Pacifique, pensamos que todos os artigos científicos devem ser facilmente acessíveis às pessoas em seu próprio idioma. Portanto, assumimos a responsabilidade de encontrar artigos na Internet de valor decente e traduzi-los para o maior número possível de idiomas, tornando-os acessíveis a muito mais pessoas do que era possível em seu idioma original.\",\n",
    "    \"abouttext-pl\":\"Journal Pacifique został utworzony, aby bariera językowa nie utrudniała dostępu do artykułów naukowych. W Journal Pacifique uważamy, że wszystkie artykuły naukowe powinny być łatwo dostępne dla ludzi w ich własnym języku. Dlatego podjęliśmy się odpowiedzialności za znalezienie artykułów w Internecie o przyzwoitej wartości i przetłumaczenie ich na jak najwięcej języków, dzięki czemu będą dostępne dla większej liczby osób niż było to możliwe w ich oryginalnym języku.\",\n",
    "    \"abouttext-zh-CN\":\"Journal Pacifique的建立是为了防止语言障碍阻碍科学文章的可访问性。 Journal Pacifique认为我们所有的科学文章都应该易于人们以自己的语言阅读。 因此，我们承担了在互联网上查找具有体面价值的文章并将其翻译成尽可能多的语言的责任，从而使更多的人可以使用原始语言。\",\n",
    "    \"abouttext-tr\":\"\",\n",
    "    \"abouttext-de\":\"Das Journal Pacifique wurde gegründet, um zu verhindern, dass die Sprachbarriere die Zugänglichkeit wissenschaftlicher Artikel behindert. Wir bei Journal Pacifique glauben, dass alle wissenschaftlichen Artikel für Menschen in ihrer eigenen Sprache leicht zugänglich sein sollten. Aus diesem Grund haben wir die Verantwortung dafür übernommen, Artikel mit angemessenem Wert im Internet zu finden und in so viele Sprachen wie möglich zu übersetzen, um sie für viel mehr Menschen zugänglich zu machen, als dies in ihrer Originalsprache möglich war.\",\n",
    "    \"abouttext-af\":\"Tydskrif Pacifique is gestig om te voorkom dat die taalversperring die toeganklikheid van wetenskaplike artikels belemmer. In Journal Pacifique glo ons dat alle wetenskaplike artikels maklik toeganklik moet wees vir mense in hul eie taal. Daarom het ons die verantwoordelikheid aanvaar om artikels met 'n ordentlike waarde op die internet te vind en dit in soveel tale as moontlik te vertaal, sodat dit vir baie meer mense toeganklik is as wat in hul oorspronklike taal moontlik was.\",\n",
    "    \n",
    "    \"see-more-es\":\"Ver más\",\n",
    "    \"see-more-pt\":\"Ver mais\",\n",
    "    \"see-more-pl\":\"Zobacz więcej\",\n",
    "    \"see-more-zh-CN\":\"看更多\",\n",
    "    \"see-more-tr\":\"Daha fazla\",\n",
    "    \"see-more-de\":\"Mehr sehen\",\n",
    "    \"see-more-af\":\"Sien meer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyhS7v6RUPR4"
   },
   "outputs": [],
   "source": [
    "def url_to_dirfile(url,target_language):\n",
    "\n",
    "    ar_di = sciencedaily_parse_article(url)\n",
    "\n",
    "    htmlx = dic_to_dirfile(ar_di,target_language, elements_dictionary)\n",
    "  \n",
    "    return [htmlx,ar_di]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UciJeDgfqz3r"
   },
   "outputs": [],
   "source": [
    "def get_article_urls_sd():\n",
    "\n",
    "    main = \"https://www.sciencedaily.com/news/top/technology/\"\n",
    "    req = Request(main, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    main_html = webpage.decode(\"utf-8\") \n",
    "    \n",
    "    links = []\n",
    "    \n",
    "    headline  = find_between(main_html, '<h5 class=\"clearfix\"><a href=\"','\">')\n",
    "    \n",
    "    for i in range(12):\n",
    "        main_html = main_html[main_html.index(headline)+len(headline):]\n",
    "        links.append(\"https://www.sciencedaily.com\"+headline)\n",
    "        headline  = find_between(main_html, '<h5 class=\"clearfix\"><a href=\"','\">')\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "un2GoaZampVw"
   },
   "outputs": [],
   "source": [
    "articles = get_article_urls_sd()\n",
    "            \n",
    "#languages = [\"es\", \"pt\", \"pl\", \"zh-CN\", \"de\", \"af\"]\n",
    "languages = [\"de\", \"af\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedaily.com/releases/2020/04/200416105650.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200416105650.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200416105650.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200416105650.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200415133657.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200416072638.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200414173251.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200403132347.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200415133440.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200413103532.htm',\n",
       " 'https://www.sciencedaily.com/releases/2020/04/200416135839.htm',\n",
       " 'https://www.sciencedaily.com/releases/2017/06/170622103824.htm']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Or4n3Fx01Mu"
   },
   "outputs": [],
   "source": [
    "#headlinessofar = []\n",
    "#articlessofar  = {}\n",
    "#articleurlssofar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlinessofar = load_obj(\"headlinessofar\")\n",
    "articlessofar = load_obj(\"articlessofar\")\n",
    "articleurlssofar =load_obj(\"articleurlssofar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refresh already saved articles' html\n",
    "#for when a design change is implemented.\n",
    "import time\n",
    "\n",
    "for article in articlessofar:\n",
    "    tmp = targdic_to_dirfile(articlessofar[article], articlessofar[article][\"lang\"], elements_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "F5uaV7Za0s9w",
    "outputId": "8f041e40-ca70-4c97-882e-9b5d0e2ac936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Erde-Größe, fanden bewohnbare Zone Planeten in frühen NASA Kepler Daten versteckt \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Aarde-grootte, bewoonbare-sone planeet gevind versteek in die vroeë NASA Kepler data \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Stärkster Beweis noch, dass Neutrinos erklären, wie das Universum existiert \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "nog sterkste bewyse dat neutrino verduidelik hoe die heelal bestaan ​​\n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "ESO-Teleskop Stern Tanz sieht um Schwarzes Loch, beweist Einstein rechts \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "ESO teleskoop sien ster dans rondom super swart gat, bewys Einstein reg \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "UV-LEDs zeigt Wirkung in corona von Oberflächen beseitigen und möglicherweise Luft und Wasser \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Ultraviolet LEDs bewys effektief in die uitskakeling van corona van oppervlaktes en, potensieel, lug en water \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "zu halten SARS-CoV-19 aus dem Wasserkreislauf Entfernen den neuartigen Coronavirus aus dem Wasserkreislauf \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Die verwydering van die roman corona van die watersiklus \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Neue Textil könnte halten Sie in der Hitze, warm in der Kälte \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Nuwe tekstiel kon hou jou koel in die hitte, warm in die koue \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Zeit auf Bildschirmen wenig Einfluss auf den Kindern soziale Fähigkeiten hat, Studie legt nahe, \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Tyd op skerms het min impak op sosiale vaardighede kinders, studie dui daarop \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Kritisch 'starbleed Anfälligkeit in FPGA-Chips identifiziert \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Kritiese 'starbleed' kwesbaarheid in FPGA skyfies geïdentifiseer \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Videospiele können Sie Ihr Gehirn \n",
      "headline\n",
      "meta\n",
      "article\n",
      "imgalt\n",
      "Video speletjies kan jou brein te verander \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "test_enable = False\n",
    "\n",
    "for article in articles:\n",
    "    if (article not in articleurlssofar) or test_enable:\n",
    "        dic = sciencedaily_parse_article(article)\n",
    "        for target_language in languages:\n",
    "                tmp = dic_to_dirfile(dic,target_language, elements_dictionary)\n",
    "                articlessofar[tmp[2]]=tmp[1]\n",
    "        articleurlssofar.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(headlinessofar,     \"headlinessofar\")\n",
    "save_obj(articlessofar,       \"articlessofar\")\n",
    "save_obj(articleurlssofar, \"articleurlssofar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLMAwueUAB1f"
   },
   "outputs": [],
   "source": [
    "#get most recent 9 articles and get their \"keys\"\n",
    "\n",
    "def form_index(target_language):\n",
    "  \n",
    "    homepage_text=\"welcome my friend we have carpets.\"\n",
    " \n",
    "    html = open(SUBFOLDER + \"jp-index.temp\").read()\n",
    "    \n",
    "    from datetime import date\n",
    "    hoy  = date.today()\n",
    "    d1   = hoy.strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    html = re.sub(r\"\\$\\$date%%\", d1, html)\n",
    "\n",
    "    html = re.sub(r\"\\$\\$home%%\",           elements_dictionary[\"homepage-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$archive%%\",        elements_dictionary[\"archive-\"+target_language],            html)\n",
    "    html = re.sub(r\"\\$\\$about%%\",          elements_dictionary[\"about us-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$jp-translation%%\", elements_dictionary[\"journal pacifique-\"+target_language],  html)\n",
    "    html = re.sub(r\"\\$\\$latest-articles%%\",elements_dictionary[\"latest-articles-\"+target_language],    html)\n",
    "    \n",
    "    #save these to elements dictionary\n",
    "    html = re.sub(r\"\\$\\$homepage-text%%\",  elements_dictionary[\"hometext-\"+target_language],    html)\n",
    "    \n",
    "    html = re.sub(r\"\\$\\$see-more%%\",  elements_dictionary[\"see-more-\"+target_language],    html)\n",
    "    \n",
    "    html = re.sub(r\"\\$\\$target-language%%\",target_language,  html)\n",
    "\n",
    "    asfl = []\n",
    "    for key in articlessofar:\n",
    "        if(articlessofar[key][\"lang\"]==target_language):\n",
    "            asfl.append(key)\n",
    "            \n",
    "    writenum = min(len(asfl),9)\n",
    "    \n",
    "    for i in range (writenum):\n",
    "        j = writenum-i\n",
    "        \n",
    "        key = asfl[i]\n",
    "    \n",
    "        html = re.sub(r\"\\$\\$article-link\"+repr(j)+\"%%\",   articlessofar[key][\"pathfromlang\"][1:],           html)\n",
    "        print(articlessofar[key][\"pathfromlang\"])\n",
    "        html = re.sub(r\"\\$\\$headline\"+repr(j)+\"%%\",           articlessofar[key][\"headline\"],           html)\n",
    "        #html = re.sub(r\"\\$\\$headlinemeta\"+repr(j)+\"%%\",           articlessofar[key][\"meta\"],           html)\n",
    "        if(articlessofar[key][\"imgaddr\"][:2]!=\"..\"):\n",
    "            html = re.sub(r\"\\$\\$headline-img\"+repr(j)+\"%%\",      articlessofar[key][\"imgaddr\"],         html)\n",
    "        else:\n",
    "            html = re.sub(r\"\\$\\$headline-img\"+repr(j)+\"%%\",      articlessofar[key][\"imgaddr\"][6:],              html)\n",
    "    \n",
    "    return html\n",
    "\n",
    "\n",
    "def refresh_indices():\n",
    "    for language in languages:\n",
    "\n",
    "        htmlx = form_index(language)\n",
    "        path  = language +\"/index.html\"\n",
    "        \n",
    "        import os\n",
    "        cmd = \"mkdir -p \"+SUBFOLDER+language\n",
    "        os.system(cmd)\n",
    "        cmd = \"touch \"+SUBFOLDER+path\n",
    "        os.system(cmd)\n",
    "        \n",
    "        f= open(SUBFOLDER+path,\"w+\")\n",
    "        f.write(htmlx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get most recent 9 articles and get their \"keys\"\n",
    "\n",
    "def form_archive(target_language):\n",
    " \n",
    "    html = open(SUBFOLDER + \"jp-archive.temp\").read()\n",
    "    \n",
    "    from datetime import date\n",
    "    hoy  = date.today()\n",
    "    d1   = hoy.strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "    html = re.sub(r\"\\$\\$date%%\", d1, html)\n",
    "\n",
    "    html = re.sub(r\"\\$\\$home%%\",           elements_dictionary[\"homepage-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$archive%%\",        elements_dictionary[\"archive-\"+target_language],            html)\n",
    "    html = re.sub(r\"\\$\\$about%%\",          elements_dictionary[\"about us-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$jp-translation%%\", elements_dictionary[\"journal pacifique-\"+target_language],  html)\n",
    "    html = re.sub(r\"\\$\\$latest-articles%%\",elements_dictionary[\"latest-articles-\"+target_language],    html)\n",
    "    \n",
    "    html = re.sub(r\"\\$\\$target-language%%\",target_language,  html)\n",
    "\n",
    "    asfl = []\n",
    "    for key in articlessofar:\n",
    "        if(articlessofar[key][\"lang\"]==target_language):\n",
    "            asfl.append(key)\n",
    "            \n",
    "    writenum = len(asfl)\n",
    "    \n",
    "    archive_text = \"\"\n",
    "    \n",
    "    for i in range (writenum):\n",
    "        j = writenum-i\n",
    "        \n",
    "        key = asfl[i]\n",
    "        \n",
    "        link = articlessofar[key][\"pathfromlang\"][1:]\n",
    "        titl = articlessofar[key][\"headline\"]\n",
    "        date = articlessofar[key][\"date\"]\n",
    "        \n",
    "        article_text = f\"<p>{date} <a href=\\\"{link}\\\" style=\\\"font-weight:900;\\\">{titl}</a></p>\\n\"\n",
    "    \n",
    "        print(article_text)\n",
    "        archive_text += article_text\n",
    "        \n",
    "    html = re.sub(r\"\\$\\$archive-text%%\",archive_text,  html)\n",
    "    \n",
    "    return html\n",
    "\n",
    "\n",
    "def refresh_archives():\n",
    "    for language in languages:\n",
    "\n",
    "        htmlx = form_archive(language)\n",
    "        path  = language +\"/archive.html\"\n",
    "        \n",
    "        import os\n",
    "        cmd = \"mkdir -p \"+SUBFOLDER+language\n",
    "        os.system(cmd)\n",
    "        cmd = \"touch \"+SUBFOLDER+path\n",
    "        os.system(cmd)\n",
    "        \n",
    "        f= open(SUBFOLDER+path,\"w+\")\n",
    "        f.write(htmlx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get most recent 9 articles and get their \"keys\"\n",
    "\n",
    "def form_about(target_language):\n",
    " \n",
    "    html = open(SUBFOLDER + \"jp-about.temp\").read()\n",
    "\n",
    "    html = re.sub(r\"\\$\\$home%%\",           elements_dictionary[\"homepage-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$archive%%\",        elements_dictionary[\"archive-\"+target_language],            html)\n",
    "    html = re.sub(r\"\\$\\$about%%\",          elements_dictionary[\"about us-\"+target_language],           html)\n",
    "    html = re.sub(r\"\\$\\$jp-translation%%\", elements_dictionary[\"journal pacifique-\"+target_language],  html)\n",
    "    \n",
    "    #save these to elements dictionary\n",
    "    html = re.sub(r\"\\$\\$about-text%%\",  elements_dictionary[\"abouttext-\"+target_language],    html)\n",
    "    \n",
    "    html = re.sub(r\"\\$\\$target-language%%\",target_language,  html)\n",
    "    \n",
    "    return html\n",
    "\n",
    "\n",
    "def refresh_abouts():\n",
    "    for language in languages:\n",
    "\n",
    "        htmlx = form_about(language)\n",
    "        path  = language +\"/about.html\"\n",
    "        \n",
    "        import os\n",
    "        cmd = \"mkdir -p \"+SUBFOLDER+language\n",
    "        os.system(cmd)\n",
    "        cmd = \"touch \"+SUBFOLDER+path\n",
    "        os.system(cmd)\n",
    "        \n",
    "        f= open(SUBFOLDER+path,\"w+\")\n",
    "        f.write(htmlx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7tM1pNHvsRo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Earth-size--habitable-zone-planet-found-hidden-in-early-NASA-Kepler-data-de.html\" style=\"font-weight:900;\">Erde-Größe, fanden bewohnbare Zone Planeten in frühen NASA Kepler Daten versteckt </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Strongest-evidence-yet-that-neutrinos-explain-how-the-universe-exists-de.html\" style=\"font-weight:900;\">Stärkster Beweis noch, dass Neutrinos erklären, wie das Universum existiert </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/ESO-telescope-sees-star-dance-around-supermassive-black-hole--proves-Einstein-right-de.html\" style=\"font-weight:900;\">ESO-Teleskop Stern Tanz sieht um Schwarzes Loch, beweist Einstein rechts </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Ultraviolet-LEDs-prove-effective-in-eliminating-coronavirus-from-surfaces-and--potentially--air-and-water-de.html\" style=\"font-weight:900;\">UV-LEDs zeigt Wirkung in corona von Oberflächen beseitigen und möglicherweise Luft und Wasser </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Removing-the-novel-coronavirus-from-the-water-cycle-de.html\" style=\"font-weight:900;\">zu halten SARS-CoV-19 aus dem Wasserkreislauf Entfernen den neuartigen Coronavirus aus dem Wasserkreislauf </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/New-textile-could-keep-you-cool-in-the-heat--warm-in-the-cold-de.html\" style=\"font-weight:900;\">Neue Textil könnte halten Sie in der Hitze, warm in der Kälte </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Time-on-screens-has-little-impact-on-kids--social-skills--study-suggests-de.html\" style=\"font-weight:900;\">Zeit auf Bildschirmen wenig Einfluss auf den Kindern soziale Fähigkeiten hat, Studie legt nahe, </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Critical--starbleed--vulnerability-in-FPGA-chips-identified-de.html\" style=\"font-weight:900;\">Kritisch 'starbleed Anfälligkeit in FPGA-Chips identifiziert </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Video-games-can-change-your-brain-de.html\" style=\"font-weight:900;\">Videospiele können Sie Ihr Gehirn </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Earth-size--habitable-zone-planet-found-hidden-in-early-NASA-Kepler-data-af.html\" style=\"font-weight:900;\">Aarde-grootte, bewoonbare-sone planeet gevind versteek in die vroeë NASA Kepler data </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Strongest-evidence-yet-that-neutrinos-explain-how-the-universe-exists-af.html\" style=\"font-weight:900;\">nog sterkste bewyse dat neutrino verduidelik hoe die heelal bestaan ​​</a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/ESO-telescope-sees-star-dance-around-supermassive-black-hole--proves-Einstein-right-af.html\" style=\"font-weight:900;\">ESO teleskoop sien ster dans rondom super swart gat, bewys Einstein reg </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Ultraviolet-LEDs-prove-effective-in-eliminating-coronavirus-from-surfaces-and--potentially--air-and-water-af.html\" style=\"font-weight:900;\">Ultraviolet LEDs bewys effektief in die uitskakeling van corona van oppervlaktes en, potensieel, lug en water </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Removing-the-novel-coronavirus-from-the-water-cycle-af.html\" style=\"font-weight:900;\">Die verwydering van die roman corona van die watersiklus </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/New-textile-could-keep-you-cool-in-the-heat--warm-in-the-cold-af.html\" style=\"font-weight:900;\">Nuwe tekstiel kon hou jou koel in die hitte, warm in die koue </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Time-on-screens-has-little-impact-on-kids--social-skills--study-suggests-af.html\" style=\"font-weight:900;\">Tyd op skerms het min impak op sosiale vaardighede kinders, studie dui daarop </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Critical--starbleed--vulnerability-in-FPGA-chips-identified-af.html\" style=\"font-weight:900;\">Kritiese 'starbleed' kwesbaarheid in FPGA skyfies geïdentifiseer </a></p>\n",
      "\n",
      "<p>2020-04-23 <a href=\"posts/2020-04-23/Video-games-can-change-your-brain-af.html\" style=\"font-weight:900;\">Video speletjies kan jou brein te verander </a></p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refresh_archives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_abouts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiGEb3gaxBDH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/posts/2020-04-23/Earth-size--habitable-zone-planet-found-hidden-in-early-NASA-Kepler-data-de.html\n",
      "/posts/2020-04-23/Strongest-evidence-yet-that-neutrinos-explain-how-the-universe-exists-de.html\n",
      "/posts/2020-04-23/ESO-telescope-sees-star-dance-around-supermassive-black-hole--proves-Einstein-right-de.html\n",
      "/posts/2020-04-23/Ultraviolet-LEDs-prove-effective-in-eliminating-coronavirus-from-surfaces-and--potentially--air-and-water-de.html\n",
      "/posts/2020-04-23/Removing-the-novel-coronavirus-from-the-water-cycle-de.html\n",
      "/posts/2020-04-23/New-textile-could-keep-you-cool-in-the-heat--warm-in-the-cold-de.html\n",
      "/posts/2020-04-23/Time-on-screens-has-little-impact-on-kids--social-skills--study-suggests-de.html\n",
      "/posts/2020-04-23/Critical--starbleed--vulnerability-in-FPGA-chips-identified-de.html\n",
      "/posts/2020-04-23/Video-games-can-change-your-brain-de.html\n",
      "/posts/2020-04-23/Earth-size--habitable-zone-planet-found-hidden-in-early-NASA-Kepler-data-af.html\n",
      "/posts/2020-04-23/Strongest-evidence-yet-that-neutrinos-explain-how-the-universe-exists-af.html\n",
      "/posts/2020-04-23/ESO-telescope-sees-star-dance-around-supermassive-black-hole--proves-Einstein-right-af.html\n",
      "/posts/2020-04-23/Ultraviolet-LEDs-prove-effective-in-eliminating-coronavirus-from-surfaces-and--potentially--air-and-water-af.html\n",
      "/posts/2020-04-23/Removing-the-novel-coronavirus-from-the-water-cycle-af.html\n",
      "/posts/2020-04-23/New-textile-could-keep-you-cool-in-the-heat--warm-in-the-cold-af.html\n",
      "/posts/2020-04-23/Time-on-screens-has-little-impact-on-kids--social-skills--study-suggests-af.html\n",
      "/posts/2020-04-23/Critical--starbleed--vulnerability-in-FPGA-chips-identified-af.html\n",
      "/posts/2020-04-23/Video-games-can-change-your-brain-af.html\n"
     ]
    }
   ],
   "source": [
    "refresh_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mo1ubDJ8qz_P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKfQHt50q0Dx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIHb6cRlepob"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TRANSLATE2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
